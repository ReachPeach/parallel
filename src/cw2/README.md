# Parallel BFS

Нужно реализовать параллельный bfs. 
От Вас требуется написать последовательную версию алгоритма  (seq) и параллельную версию (par). Протестировать надо на кубическом графе со стороной 500 и источником в (0, 0, 0). (Усреднить по 5 запускам) Сравнить время работы par на 4 процессах и seq на одном процессе - у Вас должно быть раза в 3 быстрее.  (Если будет медленнее, то выставление баллов оставляется на моё усмотрение.) Учтите, что Ваш bfs должен работать на любом графе, если Вам дан его список смежности.
Также нужно сопроводить тестами на корректность работы алгоритма.
## Структура

Все реализовано в cw2.Bfs.kt

В файлике cw2.CubeGraphFabric.kt написан типа класс-фабрика по генерации графа на гиперкубике по количеству измерений и длине его стороны

Последовательной реализации соответствуют функция seqBfs; обычный такой bfs на очереди и юзающий массив dists и как ответ, и как метки посещенности

Параллельной реализации соответствует функция parBfs; она полагается на ParallelUtils

ParallelUtils - набор функций, соответсвующих основным параллельным операциям с массивами: pfor, map, scan (двупроходый) и filter.
Map можно было бы реализовать и in-place, но чего не дано - того не дано 

В мейне сначала производится ассерт-проверка на то, что реализации реально делают бфс на кубическом графе

Затем 5 раз прогоняется на таргет графе запуск bfs для вычисления времени

---

## Обзор результатов

Результаты по запускам локально:

Для кубика (3, 300):

|                             | 1 запуск, ms | 2 запуск, ms | 3 запуск, ms | 4 запуск, ms | 5 запуск, ms | Среднее время, ms |
|-----------------------------|--------------|--------------|--------------|--------------|--------------|-------------------|
| Последовательная реализация | 53431        | 32138        | 22900        | 25199        | 28199        | 32349             |
| Параллельная реализация     | 12384        | 10339        | 8547         | 10273        | 10875        | 10483             |

В таком случае ускорение было 3,086 


Для кубика (3, 500):

|                             | 1 запуск, ms | 2 запуск, ms | 3 запуск, ms | 4 запуск, ms | 5 запуск, ms | Среднее время, ms |
|-----------------------------|--------------|--------------|--------------|--------------|--------------|-------------------|
| Последовательная реализация | 189472       | 143978       | 102592       | 112891       | 126331       | 135052            |
| Параллельная реализация     | 72343        | 69019        | 52668        | 60832        | 57370        | 62446             |

Здесь ускорение уже в 2,16 раза

---

### Вывод

- Ускорение в **2.16** раза

### Комментарии

#### Про реализацию параллельного bfs

В итоге реализовал пошаговый алгос с лекции (со сканом по degrees вершин в очереди; с фильтром по frontier-ам). Fun fact: если просто по слоям параллельно кидать вершины из следующего frontier-а в аррейлист, то получается не прям хуже..

#### Про параллельную реализацию

Решил использовать ForkJoinPool для распараллеливания, его можно сконфигурировать по количеству процессов (использую 4)

Для того, чтобы работать с ForkJoinPool, нужно определить класс таски, которую он будет обрабатывать

#### Про реализацию распараллеливаемой таски

Понятно, что мы хотим что-то типа fork2join.
Идейно было предположение, что можно делать один форк но вторую ветку добивать в этом же процессе.
На практике на производительность по времени не повлияло, но комменты в этом месте оставил (просто остались)


Реализовал таски для for-а, scan-а. Map выразил через for с неким действием, filter - компиляция уже имеющихся 

Map можно было бы делать in-place, что ускорило бы работу в общем случае. 

Scan написан двухпроходный, так что жрет память

Все это привело к тому, что на больших тестах очень много выделений памяти, и по ресурсам компа видно что это сказывается на производительности

В один момент подумал, что можно следующий frontier чистить от дубликатов - то есть, посортить первой лабой! но заметного выигрыша это не дало, тк очень мало элементов повторяется несколько раз


#### Про переход к последовательному от параллельного в тасках

В качестве границы выбрал 1024 (тесты прогонял, но там не супер репрезентативно: слишком мало - плохо, слишком много - плохо, 1024 вроде ок)


#### Беды

Я правда страдал от того, что нужно хранить такой здоровенный граф :(

---
